{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNJrjUf3OnM5QodZhi/C76K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanghae-plus-AI/AI-1-jhyeon-kim/blob/main/%EC%8B%AC%ED%99%94%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR8JER-cq_Cn",
        "outputId": "e18956f7-b11e-4b0c-f0ba-840d28453100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '2023_11_KICE_1-3', 'paragraph': '사람들이 지속적으로 책을 읽는 이유 중 하나는 즐거움이다. 독서의 즐거움에는 여러 가지가 있겠지만 그 중심에는 ‘소통의 즐거움’이 있다.독자는 독서를 통해 책과 소통하는 즐거움을 경험한다. 독서는필자와 간접적으로 대화하는 소통 행위이다. 독자는 자신이 속한사회나 시대의 영향 아래 필자가 속해 있거나 드러내고자 하는 사회나 시대를 경험한다. 직접 경험하지 못했던 다양한 삶을 필자를 매개로 만나고 이해하면서 독자는 더 넓은 시야로 세계를바라볼 수 있다. 이때 같은 책을 읽은 독자라도 독자의 배경지식이나 관점 등의 독자 요인, 읽기 환경이나 과제 등의 상황 요인이 다르므로, 필자가 보여 주는 세계를 그대로 수용하지 않고 저마다 소통 과정에서 다른 의미를 구성할 수 있다.[A] (이러한 소통은 독자가 책의 내용에 대해 질문하고 답을 찾아내는 과정에서 가능해진다. 독자는 책에서 답을 찾는 질문, 독자 자신에게서 답을 찾는 질문 등을 제기할 수 있다. 전자의 경우 책에 명시된 내용에서 답을 발견할 수 있고, 책의 내용들을 관계 지으며 답에 해당하는 내용을 스스로 구성할 수도 있다. 또한 후자의 경우 책에는 없는 독자의 경험에서 답을 찾을 수 있다. 이런 질문들을 풍부히 생성하고 주체적으로 답을 찾을 때 소통의 즐거움은 더 커진다.)한편 독자는 ㉠ (다른 독자와 소통하는 즐거움을 경험할 수도 있다.) 책과의 소통을 통해 개인적으로 형성한 의미를 독서 모임이나 독서 동아리 등에서 다른 독자들과 나누는 일이 이에 해당한다. 비슷한 해석에 서로 공감하며 기존 인식을 강화하거나 관점의 차이를 확인하고 기존 인식을 조정하는 과정에서, 독자는자신의 인식을 심화 확장할 수 있다. 최근 소통 공간이 온라인으로 확대되면서 독서를 통해 다른 독자들과 소통하며 즐거움을누리는 양상이 더 다양해지고 있다. 자신의 독서 경험을 담은 글이나 동영상을 생산 공유함으로써, 책을 읽지 않은 타인이 책과 소통하도록 돕는 것도 책을 통한 소통의 즐거움을 나누는 일이다.', 'type': 0, 'problems': [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices': ['같은 책을 읽은 독자라도 서로 다른 의미를 구성할 수 있다.', '다른 독자와의 소통은 독자가 인식의 폭을 확장하도록 돕는다', '독자는 직접 경험해 보지 못했던 다양한 삶을 책의 필자를 매개로 접할 수 있다.', '독자의 배경지식, 관점, 읽기 환경, 과제는 독자의 의미 구성에 영향을 주는 독자 요인이다.', '독자는 책을 읽을 때 자신이 속한 사회나 시대의 영향을 받으며 필자와 간접적으로 대화한다'], 'answer': 4, 'score': 2}, {'question': '다음은 학생이 독서 후 작성한 글의 일부이다. [A]를 바탕으로 ⓐ～ⓔ를 이해한 내용으로 가장 적절한 것은?', 'question_plus': \"ⓐ('음악 시간에 들었던 베토벤의 교향곡 <합창>이 위대한 작품인 이유는 무엇일까?'하는 생각)에, 베토벤에 대한 책을 빌렸다. 책에서는 기약만으로 구성됐던 교향곡에 성악을 결합헤 개성을 드러냈다는 점에서 ⓑ(이 곡이 낭만주의 음악의 특징을 보여 준다고 했다.) <합창>을 해설한 부분에 이어, 베토벤의 생애에 관한 뒷부분도 읽었는데, ⓒ(이 내용들을 종합해, 절망적 상황에서도 열정적으로 자신이 좋아하는 일을 했기에 교향곡 구성의 새로움을 보여 준 명작이 탄생했음을 알게 됐다.) 이후 ⓓ(내가 진정으로 좋아하는 일이 무엇인지 나에게 묻게 되었다.) ⓔ(글 쓰는 일에서 가장 큰 행복을 느꼈던 나를 발견)할 수 있었고, 나도 어떤 상황에서든 좋아하는 일을 계속해야겠다고 생각했다.\", 'choices': ['ⓐ와 ⓑ에는 모두 ‘독자 자신에게서 답을 찾는 질문’이 나타난다.', 'ⓒ와 ⓓ에는 모두 ‘책에 명시된 내용’에서 질문의 답을 찾아내는 모습이 나타난다.', 'ⓐ에는 ‘책에서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.', 'ⓑ에는 ‘책에서 답을 찾는 질문’이, ⓒ에는 그에 대한 답을 ‘책의 내용들을 관계 지으며’ 찾아내는 모습이 나타난다.', 'ⓓ에는 ‘독자 자신에게서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.'], 'answer': 5, 'score': 3}, {'question': '윗글을 읽고 ㉠에 대해 보인 반응으로 적절하지 않은 것은?', 'choices': ['스스로 독서 계획을 세우고 자신에게 필요한 책을 찾아 개인적으로 읽는 과정에서 경험할 수 있겠군.', '독서 모임에서 서로 다른 관점을 확인하고 자신의 관점을 조정하는 과정에서 경험할 수 있겠군.', '개인적으로 형성한 의미를, 독서 동아리를 통해 심화하는 과정에서 경험할 수 있겠군.', '자신의 독서 경험을 담은 콘텐츠를 생산하고 공유하는 과정에서 경험할 수 있겠군.', '오프라인뿐 아니라 온라인 공간에서 해석을 나누는 과정에서도 경험할 수 있겠군.'], 'answer': 1, 'score': 2}]}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Colab에 저장된 JSON 파일을 불러오기\n",
        "with open('/content/2023_11_KICE.json', 'r', encoding='utf-8') as f:\n",
        "    problems = json.load(f)\n",
        "\n",
        "# 데이터 확인 (첫 번째 문제만 출력해보기)\n",
        "print(problems[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# GPT-4 모델 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")  # GPT-2로 대체\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "# pad_token 설정을 위해 추가적으로 토크나이저를 수정\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token  # 패딩 토큰이 설정되지 않으면 eos_token으로 설정\n",
        "\n",
        "def prediction(problem):\n",
        "    \"\"\"\n",
        "    문제 데이터를 입력으로 받아 GPT 모델로 예측하는 함수.\n",
        "    문제 텍스트를 기반으로 정답 예측.\n",
        "    \"\"\"\n",
        "    # 문제의 지문 추출\n",
        "    context = problem['paragraph']\n",
        "\n",
        "    # 문제는 'problems' 리스트에 들어 있음\n",
        "    for sub_problem in problem['problems']:\n",
        "        # 해당 문제의 질문과 선택지 추출\n",
        "        question = sub_problem['question']\n",
        "        choices = sub_problem['choices']\n",
        "\n",
        "        # 문제 텍스트를 GPT 입력 형식으로 변환\n",
        "        input_text = f\"{context}\\n{question}\\n선택지: {', '.join(choices)}\\n답은?\"\n",
        "\n",
        "        # 모델 입력을 위한 토크나이징 (truncation=True와 max_length=512로 설정)\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
        "\n",
        "        # 모델이 있는 디바이스로 텐서 이동 (GPU로 이동)\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "        model.to(device)\n",
        "\n",
        "        # 모델을 통해 예측 수행 (attention_mask와 pad_token_id 설정)\n",
        "        outputs = model.generate(\n",
        "            inputs['input_ids'],\n",
        "            attention_mask=inputs['attention_mask'],\n",
        "            max_new_tokens=50,\n",
        "            pad_token_id=tokenizer.pad_token_id  # 이제 pad_token_id가 설정됨\n",
        "        )\n",
        "\n",
        "        # 생성된 텍스트 디코딩\n",
        "        prediction_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # GPT가 생성한 답을 반환\n",
        "        return prediction_text\n",
        "\n"
      ],
      "metadata": {
        "id": "h14byNIitq3O"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "def find_best_match(gpt_prediction, choices):\n",
        "    \"\"\"\n",
        "    GPT가 생성한 답과 선택지 중 가장 유사한 선택지를 찾는 함수.\n",
        "    \"\"\"\n",
        "    best_match = None\n",
        "    best_ratio = 0\n",
        "\n",
        "    for choice in choices:\n",
        "        # GPT의 생성된 텍스트와 선택지 간의 유사도 비교\n",
        "        ratio = SequenceMatcher(None, gpt_prediction, choice).ratio()\n",
        "\n",
        "        if ratio > best_ratio:\n",
        "            best_match = choice\n",
        "            best_ratio = ratio\n",
        "\n",
        "    return best_match\n",
        "\n",
        "def evaluate_model(problems):\n",
        "    correct = 0  # 맞춘 문제 수\n",
        "    total = len(problems)  # 전체 문제 수\n",
        "\n",
        "    for problem in problems:\n",
        "        # 문제의 지문 추출 (paragraph를 기반으로 예측)\n",
        "        context = problem['paragraph']\n",
        "\n",
        "        # 각 문제들에 접근 ('problems' 필드 안에 있는 문제들)\n",
        "        for sub_problem in problem['problems']:\n",
        "            # 문제의 질문과 선택지 추출\n",
        "            question = sub_problem['question']\n",
        "            choices = sub_problem['choices']\n",
        "\n",
        "            # GPT 예측 결과\n",
        "            gpt_prediction = prediction(problem)\n",
        "\n",
        "            # GPT가 생성한 답에서 가장 유사한 선택지 찾기\n",
        "            predicted_choice = find_best_match(gpt_prediction, choices)\n",
        "\n",
        "            # 정답 확인 (정답 인덱스는 1부터 시작하므로 -1)\n",
        "            if predicted_choice == choices[sub_problem['answer'] - 1]:\n",
        "                correct += 1\n",
        "\n",
        "    # 점수 계산\n",
        "    score = (correct / total) * 100\n",
        "    print(f\"GPT-4 모델의 최종 점수: {score}%\")\n",
        "    return score\n"
      ],
      "metadata": {
        "id": "0dAbwbNxt728"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(problems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENvjbwi2vj9E",
        "outputId": "95d6c001-2568-4c7d-8c9f-6a1418e78f1a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-4 모델의 최종 점수: 72.72727272727273%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72.72727272727273"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}